# Imports

import os
import pandas as pd
import numpy as np


from sklearn.linear_model import LinearRegression






# Root data Directory
# Base path
base_root = '../data/raw'

file_paths = {
    'capital': os.path.join(base_root, 'CapitalStockData.csv'),
    'energy': os.path.join(base_root, 'energy_use.csv'),
    'labor_force': os.path.join(base_root, 'labor_force.csv'),
    'patents': os.path.join(base_root, 'patents_res_nonres.csv'),
    'rnd': os.path.join(base_root, 'R&D.csv'),
    'unemployment': os.path.join(base_root, 'unemployed_ilo_estimate.csv'),
    'population': os.path.join(base_root, 'population_Data.csv'),
}


dfs = {name: pd.read_csv(path) for name, path in file_paths.items()}

# for name, df in dfs.items():
#     print(f"DataFrame name: {name}")
#     print(df.head())
#     print("\n")





def reshape_to_long(df, id_vars):
    df = df.replace('..', pd.NA)
    df_long = df.melt(id_vars=id_vars, var_name='year', value_name='value')
    df_long['year'] = df_long['year'].str.extract(r'(\d{4})').astype('Int64')
    df_long['value'] = pd.to_numeric(df_long['value'], errors='coerce')
    return df_long

def impute_group_linear(df, group_cols):
    def interpolate_numeric(g):
        g = g.sort_values('year')
        if 'value' in g.columns:
            g['value'] = g['value'].interpolate(method='linear').ffill().bfill()
        return g

    df = df.groupby(group_cols).apply(interpolate_numeric).reset_index(drop=True)
    df['value'] = df['value'].fillna(0)
    return df


processed_dfs = {}



# 1. Capital
capital_df = dfs['capital'].replace('..', pd.NA)
capital_df = capital_df.rename(columns={
    'countryname': 'country',
    'countrycode': 'country_code',
    'year': 'year'
})
# numeric_cols = capital_df.select_dtypes(include='number').columns
# capital_df[numeric_cols] = capital_df[numeric_cols].interpolate().ffill().bfill()
capital_df.fillna(0, inplace=True)

processed_dfs['capital'] = capital_df

capital_df.describe()


# 2. World Bank-style datasets
wb_datasets = ['energy', 'patents', 'rnd']
id_vars_map = {
    'Series Name': 'series_name',
    'Series Code': 'series_code',
    'Country Name': 'country',
    'countrycode': 'country_code'
}

for name in wb_datasets:
    df = dfs[name].rename(columns=id_vars_map)
    df_long = reshape_to_long(df, list(id_vars_map.values()))
    df_long = impute_group_linear(df_long, ['country', 'series_name'])
    processed_dfs[name] = df_long


# 3. Labor Force enhancement with working-age population
pop_df = dfs['population']
# Filter only the relevant series: ages 15–64
wa_series = pop_df[
    pop_df['Series Name'].isin([
        'Population ages 15-64, female',
        'Population ages 15-64, male'
    ])
]
# Standardize column names
wa_series = wa_series.rename(columns={
    'Country Name': 'country',
    'Country Code': 'country_code',
    'Series Name': 'series_name',
    'Series Code': 'series_code'
})

wa_long = reshape_to_long(wa_series, ['country', 'country_code', 'series_name', 'series_code'])

# Pivot to get female and male in separate columns
wa_pivot = wa_long.pivot_table(
    index=['country', 'country_code', 'year'],
    columns='series_name',
    values='value',
    aggfunc='first'
).reset_index()

# Calculate total working-age population
wa_pivot['working_age_population'] = (
    wa_pivot['Population ages 15-64, female'] +
    wa_pivot['Population ages 15-64, male']
)

working_age_df = wa_pivot[['country', 'country_code', 'year', 'working_age_population']]

# ---------- Labor Force Data ----------

labor_df = dfs['labor_force'].rename(columns={
    'Country Name': 'country',
    'countrycode': 'country_code',
    'Series Name': 'series_name',
    'Series Code': 'series_code'
})

labor_long = reshape_to_long(
    labor_df,
    ['series_name', 'series_code', 'country', 'country_code']
)

# ---------- Merge working-age population with labor force ----------
labor_merged = labor_long.merge(
    working_age_df,
    on=['country', 'country_code', 'year'],
    how='left'
)
labor_merged

# ---------- Train regression model using years 1990–2023 ----------
train_df = labor_merged[(labor_merged['year'] >= 1990) & (labor_merged['value'].notna())]
train_df_clean = train_df.dropna(subset=['working_age_population', 'value'])

X_train = train_df_clean[['working_age_population']]
y_train = train_df_clean['value']

model = LinearRegression()
model.fit(X_train, y_train)

# ---------- Predict labor force for years before 1990 ----------
predict_df = labor_merged[(labor_merged['year'] < 1990) & (labor_merged['working_age_population'].notna())].copy()
predict_df['predicted_labor_force'] = model.predict(predict_df[['working_age_population']])

# Merge predictions back
labor_merged = labor_merged.merge(
    predict_df[['country', 'country_code', 'year', 'predicted_labor_force']],
    on=['country', 'country_code', 'year'],
    how='left'
)

# Fill labor force with prediction if missing
labor_merged['filled_labor_force'] = labor_merged['value'].combine_first(labor_merged['predicted_labor_force'])

# ---------- Final df ----------
final_labor_df = labor_merged[[
    'series_name', 'series_code', 'country', 'country_code', 'year',
    'working_age_population', 'value', 'filled_labor_force'
]].rename(columns={
    'value': 'observed_labor_force'
})

processed_dfs['labor_force'] = final_labor_df


print(processed_dfs['capital'].describe())
processed_dfs['capital']


print(processed_dfs['energy'].describe)
processed_dfs['energy']



print(processed_dfs['patents'].describe())
processed_dfs['patents']


print(processed_dfs['rnd'].describe())
processed_dfs['rnd']


print(processed_dfs['labor_force'].describe())
processed_dfs['labor_force']






