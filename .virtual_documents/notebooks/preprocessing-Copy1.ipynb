import os
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, log, when



# Initialize Spark Session
print("[INFO] Initializing Spark Session...")
spark = SparkSession.builder.appName("GDP_Prediction_Preprocessing").getOrCreate()
print("[INFO] Spark Session created successfully.")



project_root = os.path.dirname(os.getcwd())
base_path = os.path.join(project_root, "data/raw")


# Load Capital Stock dataset
file_path = os.path.join(base_path, "CapitalStockData.csv")

print(f"[INFO] Loading dataset: Capital Stock from {file_path}")
capital_stock_df = spark.read.csv(file_path, header=True, inferSchema=True)

# Print schema and sample data
print(f"[INFO] Capital Stock dataset loaded successfully with {capital_stock_df.count()} rows.")
capital_stock_df.printSchema()
capital_stock_df.show(5)



# Load Energy Use dataset
file_path = os.path.join(base_path, "energy_use.csv")

print(f"[INFO] Loading dataset: Energy Use from {file_path}")
energy_use_df = spark.read.csv(file_path, header=True, inferSchema=True)

# Print schema and sample data
print(f"[INFO] Energy Use dataset loaded successfully with {energy_use_df.count()} rows.")
energy_use_df.printSchema()
energy_use_df.show(5)



# Load Labor Force dataset
file_path = os.path.join(base_path, "labor_force.csv")

print(f"[INFO] Loading dataset: Labor Force from {file_path}")
labor_force_df = spark.read.csv(file_path, header=True, inferSchema=True)

# Print schema and sample data
print(f"[INFO] Labor Force dataset loaded successfully with {labor_force_df.count()} rows.")
labor_force_df.printSchema()
labor_force_df.show(5)



# Load Patents dataset
file_path = os.path.join(base_path, "patents_res_nonres.csv")

print(f"[INFO] Loading dataset: Patents from {file_path}")
patents_df = spark.read.csv(file_path, header=True, inferSchema=True)

# Print schema and sample data
print(f"[INFO] Patents dataset loaded successfully with {patents_df.count()} rows.")
patents_df.printSchema()
patents_df.show(5)



# Load R&D Expenditure dataset
file_path = os.path.join(base_path, "R&D.csv")

print(f"[INFO] Loading dataset: R&D Expenditure from {file_path}")
rnd_df = spark.read.csv(file_path, header=True, inferSchema=True)

# Print schema and sample data
print(f"[INFO] R&D Expenditure dataset loaded successfully with {rnd_df.count()} rows.")
rnd_df.printSchema()
rnd_df.show(5)



# Load Unemployment dataset
file_path = os.path.join(base_path, "unemployed_ilo_estimate.csv")

print(f"[INFO] Loading dataset: Unemployment from {file_path}")
unemployment_df = spark.read.csv(file_path, header=True, inferSchema=True)

# Print schema and sample data
print(f"[INFO] Unemployment dataset loaded successfully with {unemployment_df.count()} rows.")
unemployment_df.printSchema()
unemployment_df.show(5)



# Check Missing Values
print("\n[DEBUG] Checking missing values for: Capital Stock")
capital_stock_df.select([(col(c).isNull().cast("int")).alias(c) for c in capital_stock_df.columns]).summary("count").show()

print("\n[DEBUG] Checking missing values for: Energy Use")
energy_use_df.select([(col(c).isNull().cast("int")).alias(c) for c in energy_use_df.columns]).summary("count").show()

print("\n[DEBUG] Checking missing values for: Labor Force")
labor_force_df.select([(col(c).isNull().cast("int")).alias(c) for c in labor_force_df.columns]).summary("count").show()

print("\n[DEBUG] Checking missing values for: Patents")
patents_df.select([(col(c).isNull().cast("int")).alias(c) for c in patents_df.columns]).summary("count").show()

print("\n[DEBUG] Checking missing values for: R&D Expenditure")
rnd_df.select([(col(c).isNull().cast("int")).alias(c) for c in rnd_df.columns]).summary("count").show()

print("\n[DEBUG] Checking missing values for: Unemployment")
unemployment_df.select([(col(c).isNull().cast("int")).alias(c) for c in unemployment_df.columns]).summary("count").show()



# Standardize Column Names & Handle Missing Values
print("[INFO] Standardizing column names and handling missing values for: Capital Stock")
capital_stock_df = capital_stock_df.select([col(c).alias(c.replace(" ", "_").lower()) for c in capital_stock_df.columns])

for column in capital_stock_df.columns:
    capital_stock_df = capital_stock_df.withColumn(column, when(col(column).isNull(), capital_stock_df.agg({column: "mean"}).collect()[0][0]).otherwise(col(column)))

print("[INFO] Standardization and missing value handling completed for Capital Stock")



print("[INFO] Standardizing column names and handling missing values for: Energy Use")
energy_use_df = energy_use_df.select([col(c).alias(c.replace(" ", "_").lower()) for c in energy_use_df.columns])

for column in energy_use_df.columns:
    energy_use_df = energy_use_df.withColumn(column, when(col(column).isNull(), energy_use_df.agg({column: "mean"}).collect()[0][0]).otherwise(col(column)))

print("[INFO] Standardization and missing value handling completed for Energy Use")



print("[INFO] Standardizing column names and handling missing values for: Labor Force")
labor_force_df = labor_force_df.select([col(c).alias(c.replace(" ", "_").lower()) for c in labor_force_df.columns])

for column in labor_force_df.columns:
    labor_force_df = labor_force_df.withColumn(column, when(col(column).isNull(), labor_force_df.agg({column: "mean"}).collect()[0][0]).otherwise(col(column)))

print("[INFO] Standardization and missing value handling completed for Labor Force")



print("[INFO] Standardizing column names and handling missing values for: Patents")
patents_df = patents_df.select([col(c).alias(c.replace(" ", "_").lower()) for c in patents_df.columns])

for column in patents_df.columns:
    patents_df = patents_df.withColumn(column, when(col(column).isNull(), patents_df.agg({column: "mean"}).collect()[0][0]).otherwise(col(column)))

print("[INFO] Standardization and missing value handling completed for Patents")



print("[INFO] Standardizing column names and handling missing values for: R&D Expenditure")
rnd_df = rnd_df.select([col(c).alias(c.replace(" ", "_").lower()) for c in rnd_df.columns])

for column in rnd_df.columns:
    rnd_df = rnd_df.withColumn(column, when(col(column).isNull(), rnd_df.agg({column: "mean"}).collect()[0][0]).otherwise(col(column)))

print("[INFO] Standardization and missing value handling completed for R&D Expenditure")



print("[INFO] Standardizing column names and handling missing values for: Unemployment")
unemployment_df = unemployment_df.select([col(c).alias(c.replace(" ", "_").lower()) for c in unemployment_df.columns])

for column in unemployment_df.columns:
    unemployment_df = unemployment_df.withColumn(column, when(col(column).isNull(), unemployment_df.agg({column: "mean"}).collect()[0][0]).otherwise(col(column)))

print("[INFO] Standardization and missing value handling completed for Unemployment")



dfs = {
    "Capital Stock": capital_stock_df,
    "Energy Use": energy_use_df,
    "Labor Force": labor_force_df,
    "Patents": patents_df,
    "R&D Expenditure": rnd_df,
    "Unemployment": unemployment_df
}
print("[INFO] All datasets loaded successfully.")

